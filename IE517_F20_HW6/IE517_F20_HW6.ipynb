{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('F:\\MSFE\\IE517 MLF\\HW6\\ccdefault.csv')\n",
    "df.head()\n",
    "X, y = df.iloc[:, 1:24].values, df.iloc[:,24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores_in-sample: [0.9993333333333333, 0.9993703703703704, 0.9994444444444445, 0.9994074074074074, 0.9992962962962963, 0.9992962962962963, 0.9992962962962963, 0.9993703703703704, 0.9993703703703704, 0.9993703703703704]\n",
      "accuracy scores_out-sample: [0.7243333333333334, 0.7206666666666667, 0.7216666666666667, 0.732, 0.7223333333333334, 0.7103333333333334, 0.739, 0.719, 0.7126666666666667, 0.721]\n",
      "accuracy_in-sample mean+/-std :0.999 +/- 0.000\n",
      "accuracy_out-sample mean+/-std :0.722 +/- 0.008\n",
      "[[1901  435]\n",
      " [ 402  262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      2336\n",
      "           1       0.38      0.39      0.39       664\n",
      "\n",
      "    accuracy                           0.72      3000\n",
      "   macro avg       0.60      0.60      0.60      3000\n",
      "weighted avg       0.73      0.72      0.72      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_range = range(1,11)\n",
    "score0=[]\n",
    "score1=[]\n",
    "for k in k_range:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=k)\n",
    "    dt=DecisionTreeClassifier(random_state=1)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred=dt.predict(X_test)\n",
    "    y_pred1=dt.predict(X_train)\n",
    "    score1.append(accuracy_score(y_train, y_pred1))\n",
    "    score0.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print('accuracy scores_in-sample: %s'% score1)    \n",
    "print('accuracy scores_out-sample: %s' % score0)\n",
    "print('accuracy_in-sample mean+/-std :%.3f +/- %.3f' % (np.mean(score1),np.std(score1)))\n",
    "print('accuracy_out-sample mean+/-std :%.3f +/- %.3f' % (np.mean(score0),np.std(score0)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#y_pred_prob = dt.predict_proba(X_test)[:,1]\n",
    "#fpr,tpr,thresholds = roc_curve(y_test, y_pred_prob)\n",
    "#plt.plot([0,1],[0,1],'k--')\n",
    "#plt.plot(fpr,tpr,label='DecisionTree Classifier')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('DecisionTree Classifier ROC Curve')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7233333333333334\n",
      "[[1924  412]\n",
      " [ 418  246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      2336\n",
      "           1       0.37      0.37      0.37       664\n",
      "\n",
      "    accuracy                           0.72      3000\n",
      "   macro avg       0.60      0.60      0.60      3000\n",
      "weighted avg       0.72      0.72      0.72      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SEED=42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=SEED)\n",
    "\n",
    "pipe_lr=make_pipeline(StandardScaler(),\n",
    "                    DecisionTreeClassifier(random_state=1) )\n",
    "\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred=pipe_lr.predict(X_test)\n",
    "\n",
    "print(pipe_lr.score(X_test,y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#y_pred_prob = pipe_lr.predict_proba(X_test)[:,1]\n",
    "#fpr,tpr,thresholds = roc_curve(y_test, y_pred_prob)\n",
    "#plt.plot([0,1],[0,1],'k--')\n",
    "#plt.plot(fpr,tpr,label='DecisionTree Classifier')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.title('DecisionTree Classifier ROC Curve')\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.73, 0.7344444444444445, 0.7318518518518519, 0.73, 0.7329629629629629, 0.7177777777777777, 0.7244444444444444, 0.715925925925926, 0.72, 0.7329629629629629]\n",
      "CV accuracy:0.727 +/- 0.007\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits = 10, random_state=1,shuffle=True ).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold) :\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score=pipe_lr.score(X_train[test],y_train[test])\n",
    "    scores.append(score)\n",
    "    \n",
    "print('CV accuracy scores: %s' % scores) \n",
    "\n",
    "print('CV accuracy:%.3f +/- %.3f' % (np.mean(scores),np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores_in-sample: [0.72148148 0.7237037  0.72407407 0.72037037 0.73925926 0.72555556\n",
      " 0.73333333 0.72962963 0.73444444 0.72333333]\n",
      "CV accuracy_in-sample mean+/-std :0.728 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "#CV in-sample\n",
    "scores1 = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "print('CV accuracy scores_in-sample: %s' % scores1)\n",
    "print('CV accuracy_in-sample mean+/-std :%.3f +/- %.3f' % (np.mean(scores1),np.std(scores1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores_out-sample: [0.72148148 0.7237037  0.72407407 0.72037037 0.73925926 0.72555556\n",
      " 0.73333333 0.72962963 0.73444444 0.72333333]\n",
      "CV accuracy_out-sample mean+/-std :0.736 +/- 0.017\n"
     ]
    }
   ],
   "source": [
    "#CV out-sample\n",
    "scores2 = cross_val_score(estimator=pipe_lr, X=X_test, y=y_test, cv=10, n_jobs=1)\n",
    "print('CV accuracy scores_out-sample: %s' % scores1)\n",
    "print('CV accuracy_out-sample mean+/-std :%.3f +/- %.3f' % (np.mean(scores2),np.std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Ziheng Wu\n",
      "My NetID is: zihengw5\n",
      "I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\n"
     ]
    }
   ],
   "source": [
    "print(\"My name is Ziheng Wu\")\n",
    "print(\"My NetID is: zihengw5\")\n",
    "print(\"I hereby certify that I have read the University policy on Academic Integrity and that I am not in violation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
